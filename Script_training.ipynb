{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609b9cd8",
   "metadata": {},
   "source": [
    "## 1.Convert raw datasets from hospital centers into usable variables to train our model\n",
    "    a.Import required libraries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65676ce3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wfdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3f719ca4cb76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mast\u001b[0m \u001b[1;31m#package typed-ast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wfdb'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import ast #package typed-ast\n",
    "\n",
    "#Print versions\n",
    "print('pandas version is :', pd.__version__)\n",
    "print('numpy version is :', np.__version__)\n",
    "print('wfdb version is :', wfdb.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3ba71-d021-4e3b-9769-9e29b27c7086",
   "metadata": {},
   "source": [
    "    b.Get the datas to prepare the training phase\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dbbb5a3-c949-4651-8f77-01325ccdbbaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-fe3792254291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ptbxl_database.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ecg_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscp_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscp_codes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\tfradeon\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-fe3792254291>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'ptbxl_database.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ecg_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscp_codes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscp_codes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ast' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    data = []\n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        i=0\n",
    "        for f in tqdm(df.filename_hr):\n",
    "            data.append(wfdb.rdsamp(path+f))\n",
    "            i+=1\n",
    "            if i > 2000:\n",
    "                break\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "path = './'\n",
    "sampling_rate=500\n",
    "\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "\n",
    "# Load raw signal data\n",
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_subclass)\n",
    "    return list(set(tmp))\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_subclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "# Train\n",
    "#X_train = X[np.where(Y.strat_fold != test_fold)]\n",
    "#y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n",
    "# Test\n",
    "#X_test = X[np.where(Y.strat_fold == test_fold)]\n",
    "#y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee776611-9c6b-4de4-935d-511fd9b92aaf",
   "metadata": {},
   "source": [
    "    c. Get the shape of the input and output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d6570d-cde0-4e87-b898-83c48023ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19634,)\n",
      "(19634, 5000, 12)\n",
      "(2203, 5000, 12)\n",
      "(2203,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94701fbc-39c6-4cdc-9f19-5f969500cd29",
   "metadata": {},
   "source": [
    "### Training with the Ribeiro NN Architecture\n",
    "    a.Creating the model following this format:\n",
    "![alt tag](https://user-images.githubusercontent.com/70271267/91369492-2ff41b80-e80c-11ea-9c5e-b57c6f5a9f65.png)   \n",
    "\n",
    "As we can see the model is created by \n",
    "    \n",
    "- One convolutive layer named Conv, followed by a Batch Normalization BN, and a ReLU: an activation fonction defined by: $$\\forall x \\in \\mathbb{R},f(x) = \\text{max} (x,0)$$ $$(\\text{and } f(x) \\ne 0 \\text{ only if } x > 0)$$     \n",
    "\n",
    "  \n",
    "- A residual part made by 4 ResBlk and each one contains a chaining of a Conv + BN + ReLU and a dropout (to prevent the form the over-learning). At this point the signal is smoothed, we may have lost informations so we mix it with the non-modified signal adapted to the format by a max pooling and a 1x1 Conv. We keep this signal unchanged to use it later and we use the mixed one to continue the smoothing part, with another chainin BN/ReLU/Dropout. <br/>\n",
    "\n",
    "- A dense part that convert the NN and permit a better prediction, combined with a sigmoïd fonction  that allows us to have prediction between 0 and 1.$$\\forall x \\in \\mathbb{R},\\sigma(x)= \\dfrac{1}{1 + {\\rm e}^{- x}} \\text{ and easily we have } \\forall x \\in \\mathbb{R}\\, 0\\le \\sigma(x) \\le 1  $$  \n",
    "<span style=\"color:blue\">\n",
    "(Dont forget to change the input/output size before training the model)</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58036fb7-1ea4-4870-aabc-adce228d92d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cotxetjordi/anaconda3/envs/ECG_all/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "signal (InputLayer)             [(None, 5000, 12)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 5000, 64)     12288       signal[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 5000, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 5000, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 5000, 128)    131072      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 5000, 128)    512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5000, 128)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 5000, 128)    0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 1250, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1250, 128)    262144      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1250, 128)    8192        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1250, 128)    0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1250, 128)    512         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1250, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1250, 128)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1250, 196)    401408      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1250, 196)    784         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1250, 196)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1250, 196)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 313, 128)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 313, 196)     614656      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 313, 196)     25088       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 313, 196)     0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 313, 196)     784         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 313, 196)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 313, 196)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 313, 256)     802816      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 313, 256)     1024        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 313, 256)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 313, 256)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 79, 196)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 79, 256)      1048576     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 79, 256)      50176       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 79, 256)      0           conv1d_9[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 79, 256)      1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 79, 256)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 79, 256)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 79, 320)      1310720     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 79, 320)      1280        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 79, 320)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 79, 320)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 20, 256)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 20, 320)      1638400     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 20, 320)      81920       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 20, 320)      0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 20, 320)      1280        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 20, 320)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 20, 320)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6400)         0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            32005       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,426,917\n",
      "Trainable params: 6,423,189\n",
      "Non-trainable params: 3,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model :\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from keras.layers import (Input, Conv1D, MaxPooling1D, Dropout,\n",
    "                          BatchNormalization, Activation, Add,\n",
    "                          Flatten, Dense)\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class ResidualUnit(object):\n",
    "    \"\"\"Residual unit block (unidimensional).\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples_out: int\n",
    "        Number of output samples.\n",
    "    n_filters_out: int\n",
    "        Number of output filters.\n",
    "    kernel_initializer: str, otional\n",
    "        Initializer for the weights matrices. See Keras initializers. By default it uses\n",
    "        'he_normal'.\n",
    "    dropout_rate: float [0, 1), optional\n",
    "        Dropout rate used in all Dropout layers. Default is 0.8\n",
    "    kernel_size: int, optional\n",
    "        Kernel size for convolutional layers. Default is 17.\n",
    "    preactivation: bool, optional\n",
    "        When preactivation is true use full preactivation architecture proposed\n",
    "        in [1]. Otherwise, use architecture proposed in the original ResNet\n",
    "        paper [2]. By default it is true.\n",
    "    postactivation_bn: bool, optional\n",
    "        Defines if you use batch normalization before or after the activation layer (there\n",
    "        seems to be some advantages in some cases:\n",
    "        https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md).\n",
    "        If true, the batch normalization is used before the activation\n",
    "        function, otherwise the activation comes first, as it is usually done.\n",
    "        By default it is false.\n",
    "    activation_function: string, optional\n",
    "        Keras activation function to be used. By default 'relu'.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] K. He, X. Zhang, S. Ren, and J. Sun, \"Identity Mappings in Deep Residual Networks,\"\n",
    "           arXiv:1603.05027 [cs], Mar. 2016. https://arxiv.org/pdf/1603.05027.pdf.\n",
    "    .. [2] K. He, X. Zhang, S. Ren, and J. Sun, \"Deep Residual Learning for Image Recognition,\" in 2016 IEEE Conference\n",
    "           on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778. https://arxiv.org/pdf/1512.03385.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_samples_out, n_filters_out, kernel_initializer='he_normal',\n",
    "                 dropout_rate=0.8, kernel_size=17, preactivation=True,\n",
    "                 postactivation_bn=False, activation_function='relu'):\n",
    "        self.n_samples_out = n_samples_out\n",
    "        self.n_filters_out = n_filters_out\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.kernel_size = kernel_size\n",
    "        self.preactivation = preactivation\n",
    "        self.postactivation_bn = postactivation_bn\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def _skip_connection(self, y, downsample, n_filters_in):\n",
    "        \"\"\"Implement skip connection.\"\"\"\n",
    "        # Deal with downsampling\n",
    "        if downsample > 1:\n",
    "            y = MaxPooling1D(downsample, strides=downsample, padding='same')(y)\n",
    "        elif downsample == 1:\n",
    "            y = y\n",
    "        else:\n",
    "            raise ValueError(\"Number of samples should always decrease.\")\n",
    "        # Deal with n_filters dimension increase\n",
    "        if n_filters_in != self.n_filters_out:\n",
    "            # This is one of the two alternatives presented in ResNet paper\n",
    "            # Other option is to just fill the matrix with zeros.\n",
    "            y = Conv1D(self.n_filters_out, 1, padding='same',\n",
    "                       use_bias=False, kernel_initializer=self.kernel_initializer)(y)\n",
    "        return y\n",
    "\n",
    "    def _batch_norm_plus_activation(self, x):\n",
    "        if self.postactivation_bn:\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            x = BatchNormalization(center=False, scale=False)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(self.activation_function)(x)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        \"\"\"Residual unit.\"\"\"\n",
    "        x, y = inputs\n",
    "        n_samples_in = y.shape[1].value\n",
    "        downsample = n_samples_in // self.n_samples_out\n",
    "        n_filters_in = y.shape[2].value\n",
    "        y = self._skip_connection(y, downsample, n_filters_in)\n",
    "        # 1st layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, padding='same',\n",
    "                   use_bias=False, kernel_initializer=self.kernel_initializer)(x)\n",
    "        x = self._batch_norm_plus_activation(x)\n",
    "        if self.dropout_rate > 0:\n",
    "            x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        # 2nd layer\n",
    "        x = Conv1D(self.n_filters_out, self.kernel_size, strides=downsample,\n",
    "                   padding='same', use_bias=False,\n",
    "                   kernel_initializer=self.kernel_initializer)(x)\n",
    "        if self.preactivation:\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            y = x\n",
    "            x = self._batch_norm_plus_activation(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "        else:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Add()([x, y])  # Sum skip connection and main connection\n",
    "            x = Activation(self.activation_function)(x)\n",
    "            if self.dropout_rate > 0:\n",
    "                x = Dropout(self.dropout_rate)(x)\n",
    "            y = x\n",
    "        return [x, y]\n",
    "\n",
    "\n",
    "# ----- Model ----- #\n",
    "kernel_size = 16\n",
    "kernel_initializer = 'he_normal'\n",
    "signal = Input(shape=(5000, 12), dtype=np.float32, name='signal')\n",
    "age_range = Input(shape=(5,), dtype=np.float32, name='age_range')\n",
    "is_male = Input(shape=(1,), dtype=np.float32, name='is_male')\n",
    "x = signal\n",
    "x = Conv1D(64, kernel_size, padding='same', use_bias=False,\n",
    "           kernel_initializer=kernel_initializer)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x, y = ResidualUnit(1024, 128, kernel_size=kernel_size,kernel_initializer=kernel_initializer)([x, x])\n",
    "x, y = ResidualUnit(256, 196, kernel_size=kernel_size,kernel_initializer=kernel_initializer)([x, y])\n",
    "x, y = ResidualUnit(64, 256, kernel_size=kernel_size,kernel_initializer=kernel_initializer)([x, y])\n",
    "x, _ = ResidualUnit(16, 320, kernel_size=kernel_size,kernel_initializer=kernel_initializer)([x, y])\n",
    "x = Flatten()(x)\n",
    "diagn = Dense(5, activation='sigmoid', kernel_initializer=kernel_initializer)(x)\n",
    "model = Model(signal, diagn)\n",
    "# ----------------- #\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b994c7a7-bbf8-4cf5-879d-4e982a8c81e4",
   "metadata": {},
   "source": [
    "    b. Convert the y_train into a usable format  \n",
    "    Indeed, RIbeiro uses an output shape of (None,6) and the dataset is full of output of \"[DISEASE]\" so we have to convert y_train into a list of lists that contains 6 binary information : full of 0 is the patient is healthy and 1 on the good index using this format: [\"maladies une par une\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7bd746-37ba-4f11-a607-2bfbda023b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19634, 5)\n",
      "(2203, 5)\n"
     ]
    }
   ],
   "source": [
    "#Define the diseases\n",
    "diseases = [\"NOTHING\",\"NORM\",\"MI\",\"HYP\",\"CD\",\"STTC\"]\n",
    "\n",
    "#Create a RIBEIRO format training data\n",
    "def Ribeiro_convert(y_train):\n",
    "    \n",
    "    y_train = list(y_train)\n",
    "\n",
    "    y_train_ = [[0,0,0,0,0] for i in list(y_train)]\n",
    "    for index, info in enumerate(y_train):\n",
    "\n",
    "        for disease in info:\n",
    "\n",
    "            y_train_[index][diseases.index(disease)-1] = 1\n",
    "    y_train_ = np.array(y_train_)\n",
    "    return y_train_\n",
    "\n",
    "y_train = Ribeiro_convert(y_train)\n",
    "y_test = Ribeiro_convert(y_test)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "##Reformat the ECG aquisition, 4048 samples needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9036ec-7d88-4a28-8ed7-84ce3f06f79f",
   "metadata": {},
   "source": [
    "    c. Train the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c9d8cf9-52e5-4e11-aa79-4404b213d015",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-33811e270fd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Import packages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Numpy version is :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pandas version is :'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "### Import packages \n",
    "import numpy\n",
    "print('Numpy version is :',numpy.__version__)\n",
    "import pandas as pd\n",
    "print('Pandas version is :', pd.__version__)\n",
    "import tensorflow \n",
    "print('Tenserflow version is :',tensorflow.__version__)\n",
    "import scipy\n",
    "print('Scipy version is :', scipy.__version__)\n",
    "import sklearn \n",
    "print('Scikit-learn version is :' ,sklearn.__version__)\n",
    "import tqdm \n",
    "print('tqdm version is :' ,tqdm.__version__)\n",
    "import xarray \n",
    "print('xarray version is :', xarray.__version__)\n",
    "import seaborn \n",
    "print('seaborn version is :',seaborn.__version__)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import sys     #Fait a des fonctions propres à des systèmes.\n",
    "import tensorflow.compat.v1 as tf  #Fait appel à la binliothèque Tensorflow Version 1.xx\n",
    "#tf.disable_v2_behavior()\n",
    "from keras.optimizers import Adam #On fait appel à Adam optimizer qui est une méthode de descente de gradient stochastqiue  sur une estimation des moments du premier et second ordre\n",
    "from keras.callbacks import (ModelCheckpoint,\n",
    "                             TensorBoard, ReduceLROnPlateau,\n",
    "                             CSVLogger, EarlyStopping)\n",
    "\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "opt = Adam(lr)\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=0.1,\n",
    "                               patience=7,\n",
    "                               min_lr=lr / 100),\n",
    "             EarlyStopping(patience=9,  # Patience should be larger than the one in ReduceLROnPlateau\n",
    "                           min_delta=0.00001)]\n",
    "# Set session and compile model\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))\n",
    "\n",
    "# If you are continuing an interrupted section, uncomment line bellow:\n",
    "#   model = keras.models.load_model(PATH_TO_PREV_MODEL, compile=False)\n",
    "model.compile(loss=loss, optimizer=opt)\n",
    "\n",
    "\n",
    "\n",
    "# Create log\n",
    "callbacks += [TensorBoard(log_dir='./logs', batch_size=batch_size, write_graph=False),\n",
    "              CSVLogger('training.log', append=False)]  # Change append to true if continuing training\n",
    "# Save the BEST and LAST model\n",
    "callbacks += [ModelCheckpoint('./backup_model_last.hdf5'),\n",
    "              ModelCheckpoint('./backup_model_best.hdf5', save_best_only=True)]\n",
    "# Train neural network\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=70,\n",
    "                    initial_epoch=0,  # If you are continuing a interrupted section change here\n",
    "                    validation_data = (X_test,y_test),\n",
    "                    #validation_split= 0.02,\n",
    "                    shuffle='batch',  # Because our dataset is an HDF5 file\n",
    "                    #callbacks=callbacks,\n",
    "                    verbose=1)\n",
    "# Save final result\n",
    "model.save(\"Ribeiro_model.hdf5\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6067c2f-4f09-4548-90e5-fb82540f176a",
   "metadata": {},
   "source": [
    "### Using the RIBEIRO pre-trained model\n",
    "    a. Rescale the data\n",
    "    Ribeiro is adaptated to 400Hz/10sec : 4096 samples, on this dataset the ECG are converted into 5000 samples array, we have to interpolate and convert array with shape (5000,) into (4096,)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d79a1a4-195f-407d-9eee-bfa356211946",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2e7a46ec0df7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[1;31m# opencv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mconvert_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2 # opencv\n",
    "from tqdm import tqdm\n",
    "print(X.shape)\n",
    "\n",
    "def convert_X(X,scale):\n",
    "    X_conv = np.empty((2001, 4096, 12))\n",
    "    for index,array in enumerate(X):\n",
    "        array = cv2.resize(array,(12,scale))\n",
    "        X_conv[index,:,:]=array\n",
    "    return X_conv\n",
    "    \n",
    "X_=convert_X(X,4096)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ae934-baf6-44d4-973e-78dd6148bbdd",
   "metadata": {},
   "source": [
    "#### Just to verify the interpolation, we can plot the two format, 5000 in blue and 4096 in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75eaa2ff-a57f-40f4-be6f-162fdff258ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5b64a4d12237>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCHAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mECG_12\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mECG_12\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mECG_12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "CHAR = 4096\n",
    "y = np.linspace(0,10,5000)\n",
    "y_ =np.linspace(0,10,CHAR)\n",
    "\n",
    "for index,ECG_12 in enumerate(X):\n",
    "\n",
    "        ECG_12 = np.transpose(ECG_12)\n",
    "        test = plt.figure(figsize=(20,50))\n",
    "        ECG_12_conv = np.transpose(X_[index])\n",
    "\n",
    "        for n in range(12):\n",
    "\n",
    "                plt.subplot(24,1, 2*n+1)\n",
    "                plt.plot(y,ECG_12[n])\n",
    "\n",
    "                plt.subplot(24,1,2*n+2)\n",
    "                plt.plot(y_,ECG_12_conv[n],color = \"r\")\n",
    "                break\n",
    "                \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08256cea-6ee7-4af8-9b4b-b1f9e4e33f6d",
   "metadata": {},
   "source": [
    "    b.Import the basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228b7db2-ae6f-4bb0-b884-7ca3d910472f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\tfradeon\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\tfradeon\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\tfradeon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\tfradeon\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Ribeiro model available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\tfradeon\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf  #Only call the Tensorflow Version 1.xx\n",
    "tf.disable_v2_behavior()\n",
    "import tensorflow.keras\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "import h5py\n",
    "\n",
    "model = load_model(\"C:/Users/valer/Desktop/Stage_Notebook/automatic-ecg-diagnosis-master/model/model.hdf5\")\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "print(\"Ribeiro model available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5405d7-ecf7-42c5-a5ed-451bd6611dfe",
   "metadata": {},
   "source": [
    "### Trying on a common disease to see if it works\n",
    "IRBBB are common to this dataset and Ribeiro's one, let's find out if it works on an ECG with the IRBBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a298e464-5a17-48af-8e34-ec17321e3c1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-70cba0735064>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrat_fold\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtest_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagnostic_subclass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"IRBBB\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_' is not defined"
     ]
    }
   ],
   "source": [
    "y = model.predict(X_,verbose=1)\n",
    "y_train = Y[(Y.strat_fold != test_fold)].diagnostic_subclass\n",
    "\n",
    "for ind,test in enumerate(y_train):\n",
    "    if test == [\"IRBBB\"]:\n",
    "        print(ind)\n",
    "        break\n",
    "print(y_train[49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a3753f6-555b-4b1a-a0c2-870da6924384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4581294e-04 5.6972049e-06 2.1091093e-05 8.0396585e-06 3.4746528e-04\n",
      " 1.0443233e-06]\n"
     ]
    }
   ],
   "source": [
    "print(y[49])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc745c-c6ca-4225-8b76-0ea36b5b582d",
   "metadata": {},
   "source": [
    "## Using Transfer-learning on the pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "709fb05b-bf73-4589-9c4c-5bf011d0c2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pre-trained\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "signal (InputLayer)             (None, 4096, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4096, 64)     12288       signal[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4096, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4096, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4096, 128)    131072      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4096, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4096, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096, 128)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1024, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1024, 128)    262144      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1024, 128)    8192        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1024, 128)    0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024, 128)    512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1024, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024, 128)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1024, 196)    401408      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024, 196)    784         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1024, 196)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024, 196)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 256, 128)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 256, 196)     614656      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 256, 196)     25088       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 196)     0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 196)     784         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 196)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 196)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 256, 256)     802816      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256)     1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 256)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 64, 196)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 256)      1048576     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 256)      50176       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 256)      0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 256)      1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 256)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 256)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 320)      1310720     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 320)      1280        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 320)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 320)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 16, 256)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 16, 320)      1638400     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 16, 320)      81920       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 320)      0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 320)      1280        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 320)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 320)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5120)         0           dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,394,912\n",
      "Trainable params: 0\n",
      "Non-trainable params: 6,394,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Don't take the output (6, ) part, and set trainable to False\n",
    "\n",
    "lo = []\n",
    "for layer in model.layers[:49]:\n",
    "    layer.trainable = False\n",
    "    lo.append(layer.output)\n",
    "    \n",
    "model_adaptated = keras.Model(inputs = model.input, outputs = lo,name ='pre-trained')\n",
    "\n",
    "\n",
    "model_adaptated.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1a5a42-d49f-4881-9cea-c6b235e20301",
   "metadata": {},
   "source": [
    "### Plot the convoluated image after the processing part of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cd0ec-d454-47c3-85d4-bac651263553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conv_example = model_adaptated.predict(np.array[X_[0]])\n",
    "print(conv_example.shape)\n",
    "\n",
    "\n",
    "y = np.linspace(0,10,5120)\n",
    "\n",
    "\n",
    "\n",
    "ECG_12 = np.transpose(conv_example)\n",
    "fig = plt.figure(figsize=(20,25))\n",
    "\n",
    "\n",
    "for n in range(12):\n",
    "\n",
    "        plt.subplot(6,1,n+1)\n",
    "        plt.plot(y,ECG_12[n])\n",
    "\n",
    "        if n == 6:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e85860a-01c4-43c4-b80c-c4e6ec0cd177",
   "metadata": {},
   "source": [
    "### Adding our own trainable model to fit at those new diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e8b385c-e86f-45af-bbdf-ff5eeaf13949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "signal (InputLayer)             (None, 4096, 12)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 4096, 64)     12288       signal[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4096, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 4096, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4096, 128)    131072      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 4096, 128)    512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4096, 128)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096, 128)    0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1024, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1024, 128)    262144      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1024, 128)    8192        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1024, 128)    0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1024, 128)    512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1024, 128)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024, 128)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1024, 196)    401408      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1024, 196)    784         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1024, 196)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024, 196)    0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 256, 128)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 256, 196)     614656      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 256, 196)     25088       max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 196)     0           conv1d_7[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 196)     784         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256, 196)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256, 196)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 256, 256)     802816      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256)     1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 256, 256)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256, 256)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 64, 196)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 256)      1048576     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 256)      50176       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 256)      0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 256)      1024        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 256)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 256)      0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 320)      1310720     dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 320)      1280        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 320)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 320)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 16, 256)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 16, 320)      1638400     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 16, 320)      81920       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 320)      0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 320)      1280        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 320)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 320)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5120)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 5)            25605       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,420,517\n",
      "Trainable params: 25,605\n",
      "Non-trainable params: 6,394,912\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import (Input, Conv1D, MaxPooling1D, Dropout,\n",
    "                          BatchNormalization, Activation, Add,\n",
    "                          Flatten, Dense)\n",
    "from keras.utils import plot_model\n",
    "#plot_model(model_adaptated, to_file='model.png', show_shapes=True)\n",
    "\n",
    "kernel_initializer = 'he_normal'\n",
    "x = model_adaptated.output[48]\n",
    "#x = Dense(5120, activation = 'relu',name = 'First_dense')(x)\n",
    "#x = Dense(1000, activation = 'relu',name = 'Second_dense')(x)\n",
    "preds = Dense(5,activation='sigmoid', kernel_initializer=kernel_initializer)(x)\n",
    "\n",
    "new_model = keras.Model(inputs = model_adaptated.input, outputs = preds)\n",
    "new_model.compile(loss='binary_crossentropy', optimizer=Adam(),metrics = [\"accuracy\"])\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5622b3-577d-45fe-ab77-98efbc38856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: E:\\Anaconda\\envs\\tfradeon\n",
      "\n",
      "  added / updated specs:\n",
      "    - graphviz\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2020.10.14 |                0         159 KB  anaconda\n",
      "    certifi-2020.6.20          |           py37_0         160 KB  anaconda\n",
      "    graphviz-2.38              |       hfd603c8_2        37.7 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        38.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  graphviz           anaconda/win-64::graphviz-2.38-hfd603c8_2\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.4.13-~ --> anaconda::ca-certificates-2020.10.14-0\n",
      "  certifi            pkgs/main::certifi-2020.12.5-py37haa9~ --> anaconda::certifi-2020.6.20-py37_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | #          |  10% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 159 KB    |            |   0% \n",
      "ca-certificates-2020 | 159 KB    | ####       |  40% \n",
      "ca-certificates-2020 | 159 KB    | ########## | 100% \n",
      "\n",
      "graphviz-2.38        | 37.7 MB   |            |   0% \n",
      "graphviz-2.38        | 37.7 MB   |            |   0% \n",
      "graphviz-2.38        | 37.7 MB   |            |   1% \n",
      "graphviz-2.38        | 37.7 MB   | 1          |   1% \n",
      "graphviz-2.38        | 37.7 MB   | 1          |   1% \n",
      "graphviz-2.38        | 37.7 MB   | 1          |   2% \n",
      "graphviz-2.38        | 37.7 MB   | 2          |   2% \n",
      "graphviz-2.38        | 37.7 MB   | 2          |   2% \n",
      "graphviz-2.38        | 37.7 MB   | 3          |   3% \n",
      "graphviz-2.38        | 37.7 MB   | 3          |   3% \n",
      "graphviz-2.38        | 37.7 MB   | 4          |   4% \n",
      "graphviz-2.38        | 37.7 MB   | 4          |   4% \n",
      "graphviz-2.38        | 37.7 MB   | 4          |   5% \n",
      "graphviz-2.38        | 37.7 MB   | 5          |   5% \n",
      "graphviz-2.38        | 37.7 MB   | 5          |   6% \n",
      "graphviz-2.38        | 37.7 MB   | 5          |   6% \n",
      "graphviz-2.38        | 37.7 MB   | 6          |   6% \n",
      "graphviz-2.38        | 37.7 MB   | 6          |   7% \n",
      "graphviz-2.38        | 37.7 MB   | 6          |   7% \n",
      "graphviz-2.38        | 37.7 MB   | 7          |   7% \n",
      "graphviz-2.38        | 37.7 MB   | 7          |   8% \n",
      "graphviz-2.38        | 37.7 MB   | 7          |   8% \n",
      "graphviz-2.38        | 37.7 MB   | 8          |   8% \n",
      "graphviz-2.38        | 37.7 MB   | 8          |   9% \n",
      "graphviz-2.38        | 37.7 MB   | 9          |   9% \n",
      "graphviz-2.38        | 37.7 MB   | 9          |  10% \n",
      "graphviz-2.38        | 37.7 MB   | #          |  10% \n",
      "graphviz-2.38        | 37.7 MB   | #1         |  11% \n",
      "graphviz-2.38        | 37.7 MB   | #1         |  12% \n",
      "graphviz-2.38        | 37.7 MB   | #2         |  12% \n",
      "graphviz-2.38        | 37.7 MB   | #2         |  13% \n",
      "graphviz-2.38        | 37.7 MB   | #3         |  14% \n",
      "graphviz-2.38        | 37.7 MB   | #4         |  14% \n",
      "graphviz-2.38        | 37.7 MB   | #5         |  15% \n",
      "graphviz-2.38        | 37.7 MB   | #5         |  16% \n",
      "graphviz-2.38        | 37.7 MB   | #6         |  17% \n",
      "graphviz-2.38        | 37.7 MB   | #7         |  17% \n",
      "graphviz-2.38        | 37.7 MB   | #8         |  18% \n",
      "graphviz-2.38        | 37.7 MB   | #9         |  19% \n",
      "graphviz-2.38        | 37.7 MB   | #9         |  20% \n",
      "graphviz-2.38        | 37.7 MB   | ##         |  21% \n",
      "graphviz-2.38        | 37.7 MB   | ##1        |  21% \n",
      "graphviz-2.38        | 37.7 MB   | ##2        |  22% \n",
      "graphviz-2.38        | 37.7 MB   | ##2        |  23% \n",
      "graphviz-2.38        | 37.7 MB   | ##3        |  24% \n",
      "graphviz-2.38        | 37.7 MB   | ##4        |  24% \n",
      "graphviz-2.38        | 37.7 MB   | ##5        |  25% \n",
      "graphviz-2.38        | 37.7 MB   | ##5        |  26% \n",
      "graphviz-2.38        | 37.7 MB   | ##6        |  27% \n",
      "graphviz-2.38        | 37.7 MB   | ##7        |  27% \n",
      "graphviz-2.38        | 37.7 MB   | ##8        |  28% \n",
      "graphviz-2.38        | 37.7 MB   | ##8        |  29% \n",
      "graphviz-2.38        | 37.7 MB   | ##9        |  29% \n",
      "graphviz-2.38        | 37.7 MB   | ###        |  30% \n",
      "graphviz-2.38        | 37.7 MB   | ###        |  31% \n",
      "graphviz-2.38        | 37.7 MB   | ###1       |  31% \n",
      "graphviz-2.38        | 37.7 MB   | ###1       |  32% \n",
      "graphviz-2.38        | 37.7 MB   | ###2       |  32% \n",
      "graphviz-2.38        | 37.7 MB   | ###2       |  33% \n",
      "graphviz-2.38        | 37.7 MB   | ###3       |  33% \n",
      "graphviz-2.38        | 37.7 MB   | ###3       |  34% \n",
      "graphviz-2.38        | 37.7 MB   | ###4       |  34% \n",
      "graphviz-2.38        | 37.7 MB   | ###4       |  35% \n",
      "graphviz-2.38        | 37.7 MB   | ###4       |  35% \n",
      "graphviz-2.38        | 37.7 MB   | ###5       |  35% \n",
      "graphviz-2.38        | 37.7 MB   | ###5       |  36% \n",
      "graphviz-2.38        | 37.7 MB   | ###6       |  36% \n",
      "graphviz-2.38        | 37.7 MB   | ###6       |  36% \n",
      "graphviz-2.38        | 37.7 MB   | ###6       |  37% \n",
      "graphviz-2.38        | 37.7 MB   | ###7       |  37% \n",
      "graphviz-2.38        | 37.7 MB   | ###7       |  38% \n",
      "graphviz-2.38        | 37.7 MB   | ###8       |  38% \n",
      "graphviz-2.38        | 37.7 MB   | ###8       |  39% \n",
      "graphviz-2.38        | 37.7 MB   | ###9       |  39% \n",
      "graphviz-2.38        | 37.7 MB   | ###9       |  40% \n",
      "graphviz-2.38        | 37.7 MB   | ####       |  41% \n",
      "graphviz-2.38        | 37.7 MB   | ####1      |  41% \n",
      "graphviz-2.38        | 37.7 MB   | ####1      |  42% \n",
      "graphviz-2.38        | 37.7 MB   | ####2      |  43% \n",
      "graphviz-2.38        | 37.7 MB   | ####3      |  43% \n",
      "graphviz-2.38        | 37.7 MB   | ####3      |  44% \n",
      "graphviz-2.38        | 37.7 MB   | ####4      |  45% \n",
      "graphviz-2.38        | 37.7 MB   | ####5      |  45% \n",
      "graphviz-2.38        | 37.7 MB   | ####6      |  46% \n",
      "graphviz-2.38        | 37.7 MB   | ####7      |  47% \n",
      "graphviz-2.38        | 37.7 MB   | ####8      |  48% \n",
      "graphviz-2.38        | 37.7 MB   | ####8      |  49% \n",
      "graphviz-2.38        | 37.7 MB   | ####9      |  50% \n",
      "graphviz-2.38        | 37.7 MB   | #####      |  50% \n",
      "graphviz-2.38        | 37.7 MB   | #####      |  51% \n",
      "graphviz-2.38        | 37.7 MB   | #####1     |  52% \n",
      "graphviz-2.38        | 37.7 MB   | #####2     |  52% \n",
      "graphviz-2.38        | 37.7 MB   | #####2     |  53% \n",
      "graphviz-2.38        | 37.7 MB   | #####3     |  53% \n",
      "graphviz-2.38        | 37.7 MB   | #####4     |  54% \n",
      "graphviz-2.38        | 37.7 MB   | #####4     |  55% \n",
      "graphviz-2.38        | 37.7 MB   | #####5     |  55% \n",
      "graphviz-2.38        | 37.7 MB   | #####6     |  56% \n",
      "graphviz-2.38        | 37.7 MB   | #####6     |  57% \n",
      "graphviz-2.38        | 37.7 MB   | #####7     |  57% \n",
      "graphviz-2.38        | 37.7 MB   | #####7     |  58% \n",
      "graphviz-2.38        | 37.7 MB   | #####8     |  59% \n",
      "graphviz-2.38        | 37.7 MB   | #####9     |  59% \n",
      "graphviz-2.38        | 37.7 MB   | #####9     |  60% \n",
      "graphviz-2.38        | 37.7 MB   | ######     |  60% \n",
      "graphviz-2.38        | 37.7 MB   | ######1    |  61% \n",
      "graphviz-2.38        | 37.7 MB   | ######2    |  62% \n",
      "graphviz-2.38        | 37.7 MB   | ######3    |  63% \n",
      "graphviz-2.38        | 37.7 MB   | ######3    |  64% \n",
      "graphviz-2.38        | 37.7 MB   | ######4    |  65% \n",
      "graphviz-2.38        | 37.7 MB   | ######5    |  65% \n",
      "graphviz-2.38        | 37.7 MB   | ######6    |  66% \n",
      "graphviz-2.38        | 37.7 MB   | ######6    |  67% \n",
      "graphviz-2.38        | 37.7 MB   | ######7    |  68% \n",
      "graphviz-2.38        | 37.7 MB   | ######8    |  68% \n",
      "graphviz-2.38        | 37.7 MB   | ######9    |  69% \n",
      "graphviz-2.38        | 37.7 MB   | #######    |  70% \n",
      "graphviz-2.38        | 37.7 MB   | #######    |  71% \n",
      "graphviz-2.38        | 37.7 MB   | #######1   |  72% \n",
      "graphviz-2.38        | 37.7 MB   | #######2   |  72% \n",
      "graphviz-2.38        | 37.7 MB   | #######3   |  73% \n",
      "graphviz-2.38        | 37.7 MB   | #######3   |  74% \n",
      "graphviz-2.38        | 37.7 MB   | #######4   |  74% \n",
      "graphviz-2.38        | 37.7 MB   | #######4   |  75% \n",
      "graphviz-2.38        | 37.7 MB   | #######5   |  76% \n",
      "graphviz-2.38        | 37.7 MB   | #######6   |  76% \n",
      "graphviz-2.38        | 37.7 MB   | #######6   |  77% \n",
      "graphviz-2.38        | 37.7 MB   | #######7   |  77% \n",
      "graphviz-2.38        | 37.7 MB   | #######7   |  78% \n",
      "graphviz-2.38        | 37.7 MB   | #######8   |  78% \n",
      "graphviz-2.38        | 37.7 MB   | #######9   |  79% \n",
      "graphviz-2.38        | 37.7 MB   | #######9   |  80% \n",
      "graphviz-2.38        | 37.7 MB   | ########   |  80% \n",
      "graphviz-2.38        | 37.7 MB   | ########   |  81% \n",
      "graphviz-2.38        | 37.7 MB   | ########1  |  81% \n",
      "graphviz-2.38        | 37.7 MB   | ########1  |  81% \n",
      "graphviz-2.38        | 37.7 MB   | ########1  |  82% \n",
      "graphviz-2.38        | 37.7 MB   | ########2  |  82% \n",
      "graphviz-2.38        | 37.7 MB   | ########2  |  83% \n",
      "graphviz-2.38        | 37.7 MB   | ########3  |  83% \n",
      "graphviz-2.38        | 37.7 MB   | ########3  |  84% \n",
      "graphviz-2.38        | 37.7 MB   | ########4  |  85% \n",
      "graphviz-2.38        | 37.7 MB   | ########5  |  85% \n",
      "graphviz-2.38        | 37.7 MB   | ########5  |  86% \n",
      "graphviz-2.38        | 37.7 MB   | ########6  |  86% \n",
      "graphviz-2.38        | 37.7 MB   | ########7  |  87% \n",
      "graphviz-2.38        | 37.7 MB   | ########7  |  88% \n",
      "graphviz-2.38        | 37.7 MB   | ########8  |  89% \n",
      "graphviz-2.38        | 37.7 MB   | ########9  |  89% \n",
      "graphviz-2.38        | 37.7 MB   | #########  |  90% \n",
      "graphviz-2.38        | 37.7 MB   | #########  |  91% \n",
      "graphviz-2.38        | 37.7 MB   | #########1 |  91% \n",
      "graphviz-2.38        | 37.7 MB   | #########2 |  92% \n",
      "graphviz-2.38        | 37.7 MB   | #########3 |  93% \n",
      "graphviz-2.38        | 37.7 MB   | #########3 |  94% \n",
      "graphviz-2.38        | 37.7 MB   | #########4 |  95% \n",
      "graphviz-2.38        | 37.7 MB   | #########5 |  95% \n",
      "graphviz-2.38        | 37.7 MB   | #########5 |  96% \n",
      "graphviz-2.38        | 37.7 MB   | #########6 |  97% \n",
      "graphviz-2.38        | 37.7 MB   | #########7 |  97% \n",
      "graphviz-2.38        | 37.7 MB   | #########8 |  98% \n",
      "graphviz-2.38        | 37.7 MB   | #########9 |  99% \n",
      "graphviz-2.38        | 37.7 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41deef21-325a-4a3a-896e-aa9daf184b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
